{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_1_ASSIGNMENTS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI3aAGSBZbd2"
      },
      "source": [
        "# Project 1: Convolutional Neural Network for Fashion MNIST dataset\n",
        "---\n",
        "\n",
        "## Introduction\n",
        "This report has been divided into three parts, each of which being subdivided into the seven steps of the design methodology we follow.\n",
        "\n",
        "* **1. Goals**\n",
        "* **2. Model and architecture of the CNN**\n",
        "* **3. Data preparation**\n",
        "* **4. Training procedures**\n",
        "* **5. Test and performance evaluations**\n",
        "* **6. Results, observations and conclusions**\n",
        "* **7. Full code**\n",
        "\n",
        "## 1. Goals\n",
        "The aim of this project is the construction, analysis and documentation of a convolutional neural network for the classification of clothing images from the Fashion MNIST archive. The dataset is composed by 70,000 grayscale images with 28x28 pixel resolution. The dataset is also divided into a training set (60,000) and a test set (10,000 images).\n",
        "\n",
        "## 2. Model and architecture of the CNN\n",
        "The CNN is articulated into the following layers:\n",
        "* *Convolutional 2D layer* with 20 filters of size 5x5; \n",
        "* *ReLU layer*, activation function;\n",
        "* *Max pooling 2D layer* of size 2x2 and stride = 2;\n",
        "* *Linear (fully connected) layer* with 10 nodes;\n",
        "* *Softmax layer*, activation function.\n",
        "\n",
        "![CNN Architecture](https://drive.google.com/uc?id=1EDQckhe9BXSLrlu-5DR9Pp1_dHXlrjCq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjkZNjtgaFmz"
      },
      "source": [
        "## 3. Data preparation\n",
        "\n",
        "### Initialization\n",
        "\n",
        "We import all the useful modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Jioi5craQks"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRqpkBmlai4G"
      },
      "source": [
        "Then, we define some useful constants. We will train the network for 5 epochs, a learning rate of 0.001 and a batch size of 100. If the GPU is available use it for the computation, otherwise use the CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKBuPE99am4p"
      },
      "source": [
        "# constants\n",
        "NUM_EPOCHS = 5\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "# if available use GPU, else use CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMyg2luQariu"
      },
      "source": [
        "### Load the data\n",
        "\n",
        "We load the Fashion MNIST dataset, and prepare the training set and test set. We will use the Pytorch module `torchvision.datasets`. It has many popular datasets like MNIST, FashionMNIST, CIFAR10 e.t.c."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwKllV3ma868"
      },
      "source": [
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "    root=\"./data\", \n",
        "    download=True, \n",
        "    # convert image pixel data to tensors\n",
        "    transform=transforms.Compose([transforms.ToTensor()])\n",
        "    )\n",
        "test_set = torchvision.datasets.FashionMNIST(\n",
        "    root=\"./data\", \n",
        "    download=True, \n",
        "    train=False, \n",
        "    # converting image pixel data to tensors\n",
        "    transform=transforms.Compose([transforms.ToTensor()])\n",
        "    )  \n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=BATCH_SIZE\n",
        "    )\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=BATCH_SIZE\n",
        "    )\n",
        "\n",
        "# check training set and test set size\n",
        "print(\"Training set size:\", len(train_set)) # 60000\n",
        "print(\"Test set size:\", len(test_set)) # 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0lWtf7DbYKG"
      },
      "source": [
        "### Visualize training data\n",
        "\n",
        "Let's visualize 20 random images from the training set in a 4x5 grid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaW6Bksuejlz"
      },
      "source": [
        "import random\n",
        "\n",
        "examples = enumerate(train_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "\n",
        "## TODO\n",
        "# Write the code to visualize 20 random images in a 4x5 grid.\n",
        "# Hints:\n",
        "# 1. Take the images from example_data. Notice its shape\n",
        "#    and dimension.\n",
        "# 2. The code to show the first image in example_data is\n",
        "#    plt.imshow(example_data[0][0], cmap='gray_r', interpolation='none')\n",
        "#    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UazPtfIZfD0z"
      },
      "source": [
        "## 4. Training procedures\n",
        "\n",
        "### Network architecture\n",
        "\n",
        "We define the CNN architecture. With the `print(model)` command we can visualize the network structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4XZC4jxfN4m"
      },
      "source": [
        "class FashionCNN(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(FashionCNN, self).__init__()\n",
        "        \n",
        "        ## TODO\n",
        "        # The constructor is where you instantiate all \n",
        "        # the modules. You can later access them using \n",
        "        # the same names you've given them in here.\n",
        "        #\n",
        "        # Complete the code by following the network\n",
        "        # architecture given at the beginning.\n",
        "        # Go to pytorch.org/docs/stable/nn to find the \n",
        "        # list of all pytorch layers\n",
        "\n",
        "        self.conv2d = ## hint: in_channels=1\n",
        "        self.relu = ## \n",
        "        self.maxpool2d = ## \n",
        "        self.fullyconn = nn.Linear(in_features=20*12*12, out_features=10)\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        ## TODO\n",
        "        # The forward function defines the network structure\n",
        "        # and computes output tensors from input tensors.\n",
        "        #\n",
        "        # Complete the code by listing the layers in \n",
        "        # the correct order and by passing the input \n",
        "        # through them.\n",
        "\n",
        "        out = self.conv2d(x)\n",
        "        out = self.relu(out)\n",
        "        out = ## \n",
        "\n",
        "        # Reshape the tensor to a 1-D vector for\n",
        "        # input to the fully connected layer\n",
        "        out = out.view(out.size(0), -1) \n",
        "\n",
        "        out = ## \n",
        "        out = self.softmax(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "# Create a model\n",
        "model = FashionCNN()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1wg8oEZgXMB"
      },
      "source": [
        "### Training\n",
        "\n",
        "We transfer `model` into GPU if available. We define a Loss function, in our case `CrossEntropyLoss()`, and use Adam algorithm for optimization purpose.\n",
        "\n",
        "\n",
        "We initialize some lists for storing loss and accuracy data, and execute the training by iterating over the epochs.\n",
        "\n",
        "Last, we save the trained network to file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDlwOWEagwm9"
      },
      "source": [
        "model.to(device)\n",
        "\n",
        "# Loss function\n",
        "error = nn.CrossEntropyLoss()\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Counts the number of iterations\n",
        "count = 0\n",
        "# Lists for visualization of loss and accuracy \n",
        "loss_list = []\n",
        "iteration_list = []\n",
        "accuracy_list = []\n",
        "predictions_list = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    for images, labels in train_loader:\n",
        "        # Transfering images and labels to GPU if available\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "    \n",
        "        train = Variable(images.view(100, 1, 28, 28))\n",
        "        labels = Variable(labels)\n",
        "        \n",
        "        # Forward pass \n",
        "        outputs = model(train)\n",
        "        loss = error(outputs, labels)\n",
        "        \n",
        "        # Initializing a gradient as 0 so there is no \n",
        "        # mixing of gradient among the batches\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Propagating the error backward\n",
        "        loss.backward()\n",
        "        \n",
        "        # Optimizing the parameters\n",
        "        optimizer.step()\n",
        "    \n",
        "        count += 1\n",
        "\n",
        "        #####################\n",
        "        # Testing the model #\n",
        "        #####################\n",
        "    \n",
        "        if not (count % 30): # It's same as \"if count % 30 == 0\"\n",
        "            total = 0\n",
        "            correct = 0\n",
        "        \n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "                test = Variable(images.view(100, 1, 28, 28))\n",
        "            \n",
        "                outputs = model(test)\n",
        "            \n",
        "                predictions = torch.max(outputs, 1)[1].to(device)\n",
        "                predictions_list.append(predictions)\n",
        "                correct += (predictions == labels).sum()\n",
        "            \n",
        "                total += len(labels)\n",
        "            \n",
        "            accuracy = correct * 100 / total\n",
        "            loss_list.append(loss.data)\n",
        "            iteration_list.append(count)\n",
        "            accuracy_list.append(accuracy)\n",
        "        \n",
        "    print(\"Epoch: {}, Loss: {:.3f}, Accuracy: {:.2f}%\".format(\n",
        "        epoch+1, loss.data, accuracy\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Save the model\n",
        "torch.save(model, \"saved_FashionMNIST_CNN.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tOx-Rt3mgzd"
      },
      "source": [
        "## 5. Test and performance evaluations\n",
        "\n",
        "### Loss and accuracy curves\n",
        "\n",
        "Let's plot the loss and accuracy curves during training by using the data stored in `iteration_list`, `loss_list` and `accuracy_list`.\n",
        "\n",
        "On the x-axis there is the number of iterations. Having a training set of 60 000 elements, a batch size of 100 and 5 epochs, the total number of iterations is 3000. \n",
        "\n",
        "$\\text{number of batches} = \\dfrac{\\text{samples}}{\\text{batch size}} = \\dfrac{60000}{100} = 600$\n",
        "\n",
        "$\\text{number of iterations} = \\text{epochs} \\times \\text{number of batches} = 5 \\times 600 = 3000$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b75xET_saAaz"
      },
      "source": [
        "plt.plot(iteration_list, loss_list)\n",
        "plt.xlabel(\"Number of Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.show()\n",
        "\n",
        "## TODO\n",
        "# Write the code for the accuracy graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oC5RsEED9CV"
      },
      "source": [
        "## 6. Results, observations and conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAdsP1VhjstZ"
      },
      "source": [
        "## 7. Full code\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6aQKuGiaiKl"
      },
      "source": [
        "---\n",
        "## Bibliography\n",
        "\n",
        "1. [Netron](https://netron.app/) - Visualizer for neural network, deep learning, and machine learning models.\n",
        "\n",
        "2. [Fashion MNIST with PyTorch](https://www.kaggle.com/pankajj/fashion-mnist-with-pytorch-93-accuracy)\n",
        "\n",
        "3. [MNIST Handwritten Digit Recognition in PyTorch](https://nextjournal.com/gkoehler/pytorch-mnist)"
      ]
    }
  ]
}