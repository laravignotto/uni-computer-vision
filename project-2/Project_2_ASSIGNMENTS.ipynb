{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_2_ASSIGNMENTS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQfGoK4btj8h"
      },
      "source": [
        "# Project 2: Denoising Neural Network for Fashion MNIST Dataset\n",
        "\n",
        "---\n",
        "\n",
        "## Introduction\n",
        "This report has been divided into three parts, each of which being subdivided into the seven steps of the design methodology we follow.\n",
        "\n",
        "* **1. Goals**\n",
        "* **2. Model and architecture of the Network**\n",
        "* **3. Data preparation**\n",
        "* **4. Training procedures**\n",
        "* **5. Test and performance evaluations**\n",
        "* **6. Results, observations and conclusions**\n",
        "* **7. Full code**\n",
        "\n",
        "## 1. Goals\n",
        "The aim of this project is to implement and train a Denoising Convolutional Autoencoder Network for image reconstruction, and to test it and analyze the results. We will use the Fashion MNIST image dataset and manually add noise to the images.\n",
        "\n",
        "By giving noisy images as inputs to the Autoencoder NN, the encoder part will compress them, and the decoder will reconstruct the original denoised images from the compressed representation. Finally, we will see how well the model performs after training by giving it some test images for denoising and reconstruction.\n",
        "\n",
        "## 2. Model and architecture of the Network\n",
        "The Autoencoder NN is divided into an encoder part and a symmetric decoder part.\n",
        "* **Encoder layers**\n",
        "  * *Convolutional layer 1*: input channels = 1 (grayscale image), output channels = 64 (number of kernels), kernel size = 3, padding = 1; \n",
        "  * *Convolutional layer 2*: input channels = 64, output channels = 32, kernel size = 3, padding = 1;\n",
        "  * *Convolutional layer 3*: input channels = 32, output channels = 16, kernel size = 3, padding = 1;\n",
        "  * *Convolutional layer 4*: input channels = 16, output channels = 8, kernel size = 3, padding = 1;\n",
        "  * *Max Pooling layer*: size = 2x2;\n",
        "* **Decoder layers**\n",
        "  * *Transposed Convolutional layer 1*:  input channels = 8, output channels = 8, kernel size = 3, stride = 2;\n",
        "  * *Transposed Convolutional layer 2*:  input channels = 8, output channels = 16, kernel size = 3, stride = 2;\n",
        "  * *Transposed Convolutional layer 3*:  input channels = 16, output channels = 32, kernel size = 2, stride = 2;\n",
        "  * *Transposed Convolutional layer 4*:  input channels = 32, output channels = 64, kernel size = 2, stride = 2;\n",
        "  * *Convolutional layer (output)*:  input channels = 64, output channels = 1, kernel size = 3, padding = 1.\n",
        "\n",
        "Each of the encoding layers is passed through the ReLU activation function, and there is a max pooling layer after each convolutional layer. After the last pooling layer we get the latent space code representation of the input data.\n",
        "\n",
        "Similarly, every transposed convolutional layer is passed through the ReLU function, and the final convolutional layer uses the sigmoid activation function.\n",
        "\n",
        "![Trained CNN Architecture](https://drive.google.com/uc?id=1cqMWn13qhPi5Cb3eMiXeJhyedJR460Pa)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jslIWgiIu97R"
      },
      "source": [
        "## 3. Data preparation\n",
        "\n",
        "### Imports and costants\n",
        "\n",
        "First, we import all the useful modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HktSL6uyiVB"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd82hRHu10ry"
      },
      "source": [
        "Then, we define some useful constants. We will train the network for 8 epochs, with a learning rate of 0.001 and a batch size of 16. The `NOISE_FACTOR` defines the amount of noise we will add to the images.\n",
        "\n",
        "We will use the GPU for the computation if available, otherwise the CPU will be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxcLA6viyoeY"
      },
      "source": [
        "## TODO\n",
        "# define the constants\n",
        "NOISE_FACTOR = 0.1\n",
        "\n",
        "## TODO\n",
        "# define the device (GPU, else CPU)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06Klf1iC24fm"
      },
      "source": [
        "### Load the data\n",
        "\n",
        "We prepare the training set and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elLo4C3ryu20"
      },
      "source": [
        "# transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # converting image pixel data to tensors\n",
        "    transforms.Normalize((0.5,), (0.5,)), # normalizing in the range [0,1]\n",
        "])\n",
        "\n",
        "## TODO\n",
        "# 1. Load train_set and test_set (use transform=transform),\n",
        "#    and define train_loader and test_loader (also\n",
        "#    use shuffle=True).\n",
        "# 2. Check training set and test set size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx9cdaxs4Fk2"
      },
      "source": [
        "### Visualize training data\n",
        "\n",
        "Let's visualize 20 random images from the training set, with their respective label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgj4YFnyy_tb"
      },
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 5, 4\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_set), size=(1,)).item()\n",
        "    img, label = train_set[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray_r\")\n",
        "plt.show()\n",
        "\n",
        "## TODO (optional)\n",
        "# You can visualize 20 random images as we did in Project 1,\n",
        "# or alternatively you can write your own original code."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALwxei4S4bUq"
      },
      "source": [
        "## 4. Training procedures\n",
        "\n",
        "### Define the autoencoder NN architecture\n",
        "\n",
        "We define all the layers we will require in the `Autoencoder` class constructor, and build the neural network in the `forward()` function.\n",
        "\n",
        "We istantiate a `model` object and print it to see the architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzRInK51zlI4"
      },
      "source": [
        "# the autoencoder network\n",
        "class Autoencoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        ## TODO\n",
        "        # Go to pytorch.org/docs/stable/nn to find the \n",
        "        # list of all pytorch layers\n",
        "\n",
        "        # Instantiate the encoder layers (4 conv layers\n",
        "        # and 1 maxpool layer) as stated at the beginning\n",
        "        # ...\n",
        "\n",
        "        # Instantiate the decoder layers (4 conv transpose \n",
        "        # layers, use nn.ConvTranspose2d, and 1 conv layer) \n",
        "        # as stated at the beginning\n",
        "        # ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        ## TODO\n",
        "        # Encoding\n",
        "        # Remember: each of the encoding layers is passed  \n",
        "        # through the ReLU activation function, and there \n",
        "        # is a max pooling layer after every conv layer.\n",
        "        out = torch.nn.functional.relu(self.enc1(x))\n",
        "        out = self.pool(x)\n",
        "        # ...\n",
        "        out = self.pool(x) # latent space representation\n",
        "        \n",
        "        # Decoding\n",
        "        # Remember: every transposed convolutional layer \n",
        "        # is passed through the ReLU function, and the \n",
        "        # final convolutional layer uses the sigmoid \n",
        "        # activation function.\n",
        "        # ...\n",
        "\n",
        "        return out\n",
        "\n",
        "# create a model\n",
        "model = Autoencoder()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWhjDhIE6Iw_"
      },
      "source": [
        "### Training\n",
        "\n",
        "We will write the training function. First, we define the loss function, in our case the Mean Squared Error, and the optimization algorithm, Adam.\n",
        "\n",
        "The training function loops over the epochs and batch by batch. It returns the training loss data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7jcqtL_0NaJ"
      },
      "source": [
        "## TODO\n",
        "# Write the loss function and the optimizer\n",
        "\n",
        "# the training function\n",
        "def train(model, train_loader, NUM_EPOCHS):\n",
        "    train_loss = []\n",
        "    iteration = 0\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        running_loss = 0.0\n",
        "        for data in train_loader:\n",
        "            img, _ = data # we do not need the image labels\n",
        "\n",
        "            # add noise to the image data\n",
        "            img_noisy = img + NOISE_FACTOR * torch.randn(img.shape)\n",
        "\n",
        "            # clip to make the values fall between 0 and 1\n",
        "            img_noisy = np.clip(img_noisy, 0., 1.)\n",
        "\n",
        "            # load the noisy images to the computation device \n",
        "            img_noisy = img_noisy.to(device)\n",
        "            \n",
        "            ## TODO\n",
        "            # 1. Set the gradients to zero.\n",
        "            # 2. Forward pass. Remember: the MSE is calculated\n",
        "            #    between the outputs and the noisy images.\n",
        "            # 3. Backpropagate.\n",
        "            # 4. Optimize (update) the parameters.\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        loss = running_loss / len(train_loader)\n",
        "        train_loss.append(loss)\n",
        "        print('Epoch {} of {}, Train Loss: {:.4f}'.format(epoch+1, NUM_EPOCHS, loss))\n",
        "\n",
        "    return train_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQw2kkufncgT"
      },
      "source": [
        "We call the `train` function and execute the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InacR94GbgNH"
      },
      "source": [
        "## TODO\n",
        "# 1. Transfer the model to the GPU if available.\n",
        "# 2. Execute the training by calling the train function\n",
        "#    and storing the result into a variable (it returns\n",
        "#    train_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p37Qe1PJgLlb"
      },
      "source": [
        "## 5. Test and performance evaluations\n",
        "\n",
        "### Loss curve\n",
        "\n",
        "We plot the training loss data over the epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhMQqu8zb5Fv"
      },
      "source": [
        "## TODO\n",
        "# Plot the training loss curve. The data is stored\n",
        "# into the variable created in the previous step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt8rKNNpn-XW"
      },
      "source": [
        "### Image reconstruction\n",
        "\n",
        "We define a new function, `test_image_reconstruction`, that adds noise to images never given as inputs to the network, and performs the image reconstructions for just one batch.\n",
        "\n",
        "It also visualizes 5 noisy images and their reconstructions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIoCClPP0WH5"
      },
      "source": [
        "def test_image_reconstruction(model, test_loader):\n",
        "    for batch in test_loader:\n",
        "        img, _ = batch\n",
        "        # add noise to the images\n",
        "        img_noisy = img + NOISE_FACTOR * torch.randn(img.shape)\n",
        "        img_noisy = np.clip(img_noisy, 0., 1.)\n",
        "        img_noisy = img_noisy.to(device)\n",
        "        outputs = model(img_noisy)\n",
        "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
        "        break\n",
        "\n",
        "    # visualize noisy and reconstructed images\n",
        "    img_noisy = img_noisy.cpu().data\n",
        "    figure = plt.figure(figsize=(10, 5))\n",
        "    cols, rows = 5, 2\n",
        "    for i in range(cols):\n",
        "        # noisy images\n",
        "        figure.add_subplot(rows, cols, i+1)\n",
        "        img_noisy_show = img_noisy[i, :, :, :].permute(1, 2, 0) \n",
        "        plt.title(\"noisy\")\n",
        "        plt.imshow(np.squeeze(img_noisy_show), cmap=\"gray_r\")\n",
        "        # reconstructed images\n",
        "        figure.add_subplot(rows, cols, i+cols+1)\n",
        "        outputs_show = outputs[i, :, :, :].permute(1, 2, 0)\n",
        "        plt.title(\"reconstructed\") \n",
        "        plt.imshow(np.squeeze(outputs_show), cmap=\"gray_r\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE2ihr0Jo2Z8"
      },
      "source": [
        "Let's call the test function, print the images, and save the trained network to file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDsryy3Fb_XV"
      },
      "source": [
        "test_image_reconstruction(model, test_loader)\n",
        "\n",
        "## TODO\n",
        "# save the trained network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVVKoTewRPTA"
      },
      "source": [
        "## 6. Results, observations and conclusions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH9Tu0Nlth1h"
      },
      "source": [
        "## 7. Full code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LxQdK5zMc7W"
      },
      "source": [
        "---\n",
        "## Bibliography\n",
        "\n",
        "1. [Netron](https://netron.app/) - Visualizer for neural network, deep learning, and machine learning models.\n",
        "\n",
        "2. [Autoencoder Neural Network: Application to Image Denoising](https://debuggercafe.com/autoencoder-neural-network-application-to-image-denoising/)"
      ]
    }
  ]
}